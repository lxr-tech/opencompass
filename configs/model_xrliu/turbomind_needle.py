from opencompass.models import TurboMindModelLong

path_dict = {'llama2_7B': '', 
             'llama2_7B_chat': '', 
             'llama2_13B': '', 
             'llama3_8B': '/cpfs01/shared/alillm2/llm_llama3_hf/Meta-Llama-3-8B/', 
             'llama3_8B_chat': '/cpfs01/shared/alillm2/llm_llama3_hf/Meta-Llama-3-8B-Instruct/', 
             'llama3_1_8B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--meta-llama--Meta-Llama-3.1-8B/snapshots/48d6d0fc4e02fb1269b36940650a1b7233035cbb/', 
             'llama3_1_8B_chat': '/nas/shared/public/llmeval/model_weights/hf_hub/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/07eb05b21d191a58c577b4a45982fe0c049d0693/', 
             'llama3_1_70B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--meta-llama--Meta-Llama-3.1-70B/snapshots/7740ff69081bd553f4879f71eebcc2d6df2fbcb3/', 
             'internlm2_1B': '',
             'internlm2_1B_base': '',
             'internlm2_7B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--internlm--internlm2-7b/snapshots/fa732f7cd8ec6299400e37e790ecd82abb1a7f9a/',
             'internlm2_7B_base': '',  
             'internlm2_7B_chat': '',
             'internlm2_20B': '',
             'internlm2.5_7B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--internlm--internlm2_5-7b/snapshots/7bee5c5d7c4591d7f081f5976610195fdd1f1e35/',  # '/nas/shared/alillm2/zhangshuo/exported_transformers/official_Ampere2.5_7B_Enhance_2.0.0/50000/', 
             'internlm2.5_7B_enhance': '/cpfs01/shared/public/chenzhi/ckpts/internlm2_5_hf', 
             'internlm2.5_7B_chat': '/nas/shared/public/llmeval/model_weights/hf_hub/models--internlm--internlm2_5-7b-chat-1m/snapshots/8d1a709a04d71440ef3df6ebbe204672f411c8b6/', 
             'internlm2.5_7B_chat_old': '/nas/shared/public/llmeval/model_weights/hf_hub/models--internlm--internlm2_5-7b-chat/snapshots/d201a0f94e117dcfc20c1232798fe88e28659b52/', 
             'qwen2_1B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--Qwen--Qwen2-1.5B/snapshots/8a16abf2848eda07cc5253dec660bf1ce007ad7a/', 
             'qwen2_1B_chat': '/nas/shared/public/llmeval/model_weights/hf_hub/models--Qwen--Qwen2-1.5B-Instruct/snapshots/ba1cf1846d7df0a0591d6c00649f57e798519da8/', 
             'qwen2_7B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--Qwen--Qwen2-7B/snapshots/d8412313bc00677839b4e38cdc751d536ccc12ab/', 
             'qwen2_7B_chat': '/nas/shared/public/llmeval/model_weights/hf_hub/models--Qwen--Qwen2-7B-Instruct/snapshots/6ddb532fa75db9a1269de86eaa579818eb39743a/', 
             'qwen2_72B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--Qwen--Qwen2-72B/snapshots/e5cebedf0244946b1ad5eb2d753ca3c1a90f11fb/', 
             'mistral3_7B': '/nas/shared/public/llmeval/model_weights/hf_hub/models--mistralai--Mistral-7B-v0.3/snapshots/b67d6a03ca097c5122fa65904fce0413500bf8c8/', 
             'mistral3_7B_chat': '/nas/shared/public/llmeval/model_weights/hf_hub/models--mistralai--Mistral-7B-Instruct-v0.3/snapshots/83e9aa141f2e28c82232fea5325f54edf17c43de/', 
             'glm4_9B_chat_1M': '/nas/shared/public/llmeval/model_weights/hf_hub/models--THUDM--glm-4-9b-chat-1m/snapshots/715ddbe91082f976ff6a4ca06d59e5bbff6c3642/', 

             'tj_sft_240828': '/cpfs01/shared/public/public_hdd/tongjian/hf_model/Ampere_7B_v1.1_sft2stage_FT_LongAlign_baseline/450', 

             'cz_sushi_24082901': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v43_0_0/hf_600', 
             'cz_sushi_24090401': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v49_0_0/200_internlm2_5_hf', 
             'cz_sushi_24090402': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v49_0_0/600_internlm2_5_hf', 

             'cz_sushi_7B_v50_0_0_600': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v50_0_0/600_internlm2_5_hf', 
             'cz_sushi_7B_v50_0_0_1200': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v50_0_0/1200_internlm2_5_hf', 

             'cz_sushi_7B_v51_0_0_400': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v51_0_0/400_internlm2_5_hf', 
             'cz_sushi_7B_v51_0_0_800': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v51_0_0/800_internlm2_5_hf', 
             'cz_sushi_7B_v51_0_0_1200': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v51_0_0/1200_internlm2_5_hf', 

             'cz_sushi_7B_v52_0_0_600': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v52_0_0/600_internlm2_5_hf', 
             'cz_sushi_7B_v52_0_0_1000': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v52_0_0/1000_internlm2_5_hf', 
             'cz_sushi_7B_v52_0_0_1400': '/cpfs01/shared/public/chenzhi/ckpts/Sushi_7B_v52_0_0/1400_internlm2_5_hf', 

             'sdm_24090101': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500/52500_hf', 
             'sdm_24090102': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500_NeedleFix_hf/', 
             'sdm_24090103': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_3.0.0_256K_hf/original/', 
             'sdm_24090101d2': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500/dynamic', 
             'sdm_24090102d2': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500_NeedleFix_hf/dynamic', 
             'sdm_24090103d2': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_3.0.0_256K_hf/dynamic/', 
             'sdm_24090102d3': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500_NeedleFix_hf/dynamic_v2', 
             'sdm_24090103d3': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/official_Ampere2.5_7B_3.0.0_256K_hf/dynamic_v2/', 

             'sdm_24090601a': '/cpfs01/shared/public/liuxiaoran/ckpt_from_demin/volc_official_Ampere2.5_7B_Enhance_256k.0.0.0_FixBBHLeak_wsd_from_50000_to_52500_NeedleFix_fsp_s2_internlm2_5_420_hf/', 
            }

num_gpus = {'llama2_7B': 4, 'llama2_7B_chat': 4, 'llama2_13B': 8, 
            'llama3_8B': 4, 'llama3_8B_chat': 4, 'llama3_1_8B': 4, 'llama3_1_8B_chat': 4, 'llama3_1_70B': 8, 
            'qwen1.5_1B': 4, 'qwen1.5_7B': 4, 'qwen1.5_14B': 8, 'qwen1.5_32B': 8, 'internlm2.5_7B_enhance': 4, 
            'qwen2_1B': 4, 'qwen2_1B_chat': 4, 'qwen2_7B': 4, 'qwen2_7B_chat': 4, 'qwen2_72B': 8, 
            'internlm2_7B': 4, 'internlm2_7B_chat': 4, 
            'internlm2.5_7B': 4, 'internlm2.5_7B_chat': 4, 
            'internlm2_1B': 4, 'internlm2_20B': 4, 
            'mistral3_7B': 4, 'mistral3_7B_chat': 4, 
            'glm4_9B_chat_1M': 4, 
            }

tags = [
        # ('', 'llama3_1_8B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'llama3_1_8B_chat', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'internlm2.5_7B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'internlm2.5_7B_chat', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'internlm2.5_7B_chat_old', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'qwen2_7B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'qwen2_1B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'qwen2_1B_chat', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'qwen2_7B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'qwen2_7B_chat', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 

        # ('', 'tj_sft_240828', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'internlm2_7B', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_24082901', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_24090401', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_24090402', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 

        # ('', 'internlm2.5_7B_chat', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        ('', 'internlm2.5_7B_enhance', -1, 
         dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v51_0_0_400', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v51_0_0_800', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v51_0_0_1200', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v50_0_0_600', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v52_0_0_600', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v52_0_0_1000', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 
        # ('', 'cz_sushi_7B_v52_0_0_1400', -1, 
        #  dict(rope_scaling_factor=2.5, session_len=400000, max_batch_size=1)), 

        # ('', 'sdm_24090103', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'sdm_24090104', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'sdm_24090101d2', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'sdm_24090102d2', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'sdm_24090103d2', -1, 
        #  dict(session_len=400000, max_batch_size=1)), 
        # ('', 'sdm_24090102d3', -1, 
        #  dict(session_len=1124000, max_batch_size=1, cache_max_entry_count=0.5, tp=8)), 
        # ('', 'sdm_24090103d3', -1, 
        #  dict(session_len=1124000, max_batch_size=1, cache_max_entry_count=0.5, tp=8)), 

        # ('', 'sdm_24090601a', -1, 
        #  dict(session_len=1124000, max_batch_size=1, cache_max_entry_count=0.5, tp=8)), 

    ]

models = []

for abbr, group, cat_len, engine_config in tags:
    models.append(
        dict(
            type=TurboMindModelLong,
            abbr=f'{group}{abbr}',
            path=path_dict[group],
            engine_config=engine_config,
            gen_config=dict(top_k=1, temperature=1e-6, top_p=0.9, max_new_tokens=2048),
            max_seq_len=1048576,
            max_out_len=50,
            batch_size=1,
            run_cfg=dict(num_gpus=1,  # num_gpus[group.split('-')[0]], 
                         ),
        )
    )